{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67a95c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50b5054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d6f0f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import argparse\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard, CSVLogger\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import csv\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras import backend as K\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "import requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52184a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global paths\n",
    "OUTPUT_DIRECTORY = \"./outputs/\"\n",
    "LABEL_DIRECTORY = \"./labels/\"\n",
    "MODEL_DIRECTORY = \"./models/\"\n",
    "MODEL_GD_ID = \"1MRbN5hXOTYnw7-71K-2vjY01uJ9GkQM5\"\n",
    "MODEL_ZIP_FILE = \"./models/models.zip\"\n",
    "IMG_DIRECTORY = \"./images/\"\n",
    "IMG_GD_ID = \"1xnK3B6K6KekDI55vwJ0vnc2IGoDga9cj\"\n",
    "IMG_ZIP_FILE = \"./images/images.zip\"\n",
    "\n",
    "# Global variables\n",
    "RAW_IMG_SIZE = (256, 256)\n",
    "IMG_SIZE = (224, 224)\n",
    "INPUT_SHAPE = (IMG_SIZE[0], IMG_SIZE[1], 3)\n",
    "MAX_EPOCH = 200\n",
    "BATCH_SIZE = 32\n",
    "FOLDS = 5\n",
    "STOPPING_PATIENCE = 32\n",
    "LR_PATIENCE = 16\n",
    "INITIAL_LR = 0.0001\n",
    "CLASSES = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "CLASS_NAMES = ['Chinee Apple',\n",
    "               'Lantana',\n",
    "               'Parkinsonia',\n",
    "               'Parthenium',\n",
    "               'Prickly Acacia',\n",
    "               'Rubber Vine',\n",
    "               'Siam Weed',\n",
    "               'Snake Weed',\n",
    "               'Negatives']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aecb4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_google_drive_file(id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "    save_response_content(response, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2b3581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79fd018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e229ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Train and test ResNet50, InceptionV3, or custom model on DeepWeeds.')\n",
    "    parser.add_argument(\"command\", default='train', help=\"'cross_validate' or 'inference'\")\n",
    "    parser.add_argument('--model', default='resnet', help=\"'resnet', 'inception', or path to .hdf5 file.\")\n",
    "    args = parser.parse_args()\n",
    "    return args.command, args.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63da09d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images():\n",
    "    if not os.path.exists(IMG_DIRECTORY):\n",
    "        os.makedirs(IMG_DIRECTORY)\n",
    "        print(\"Downloading DeepWeeds images to \" + IMG_ZIP_FILE)\n",
    "        download_google_drive_file(IMG_GD_ID, IMG_ZIP_FILE)\n",
    "        print(\"Finished downloading images.\")\n",
    "        print(\"Unzipping \" + IMG_ZIP_FILE)\n",
    "        with ZipFile(IMG_ZIP_FILE, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(IMG_DIRECTORY)\n",
    "        print(\"Finished unzipping images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec2324a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_models():\n",
    "    if not os.path.exists(MODEL_DIRECTORY):\n",
    "        os.makedirs(MODEL_DIRECTORY)\n",
    "        print(\"Downloading DeepWeeds models to \" + MODEL_ZIP_FILE)\n",
    "        download_google_drive_file(MODEL_GD_ID, MODEL_ZIP_FILE)\n",
    "        print(\"Finished downloading models.\")\n",
    "        print(\"Unzipping \" + MODEL_ZIP_FILE)\n",
    "        with ZipFile(MODEL_ZIP_FILE, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(MODEL_DIRECTORY)\n",
    "        print(\"Finished unzipping models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70980ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def crop(img, size):\n",
    "    \"\"\"\n",
    "    Crop the image concentrically to the desired size.\n",
    "    :param img: Input image\n",
    "    :param size: Required crop image size\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    (h, w, c) = img.shape\n",
    "    x = int((w - size[0]) / 2)\n",
    "    y = int((h - size[1]) / 2)\n",
    "    return img[y:(y + size[1]), x:(x + size[0]), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a74cfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def crop_generator(batches, size):\n",
    "    \"\"\"\n",
    "    Take as input a Keras ImageGen (Iterator) and generate random\n",
    "    crops from the image batches generated by the original iterator\n",
    "    :param batches: Batches of images to be cropped\n",
    "    :param size: Size to be cropped to\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        batch_x, batch_y = next(batches)\n",
    "        (b, h, w, c) = batch_x.shape\n",
    "        batch_crops = np.zeros((b, size[0], size[1], c))\n",
    "        for i in range(b):\n",
    "            batch_crops[i] = crop(batch_x[i], (size[0], size[1]))\n",
    "        yield (batch_crops, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a396f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(model_name):\n",
    "\n",
    "    # K fold cross validation, saving outputs for each fold\n",
    "    for k in range(FOLDS):\n",
    "\n",
    "        # Create new output directory for individual folds from timestamp\n",
    "        timestamp = datetime.fromtimestamp(time()).strftime('%Y%m%d-%H%M%S')\n",
    "        print('Fold {}/{} - {}'.format(k + 1, FOLDS, timestamp))\n",
    "        output_directory = \"{}{}/\".format(OUTPUT_DIRECTORY, timestamp)\n",
    "        if not os.path.exists(output_directory):\n",
    "            os.makedirs(output_directory)\n",
    "\n",
    "        # Prepare training, validation and testing labels for kth fold\n",
    "        train_label_file = \"{}train_subset{}.csv\".format(LABEL_DIRECTORY, k)\n",
    "        val_label_file = \"{}val_subset{}.csv\".format(LABEL_DIRECTORY, k)\n",
    "        test_label_file = \"{}test_subset{}.csv\".format(LABEL_DIRECTORY, k)\n",
    "        train_dataframe = pd.read_csv(train_label_file)\n",
    "        val_dataframe = pd.read_csv(val_label_file)\n",
    "        test_dataframe = pd.read_csv(test_label_file)\n",
    "        train_image_count = train_dataframe.shape[0]\n",
    "        val_image_count = train_dataframe.shape[0]\n",
    "        test_image_count = test_dataframe.shape[0]\n",
    "\n",
    "        # Training image augmentation\n",
    "        train_data_generator = ImageDataGenerator(\n",
    "            rescale=1. / 255,\n",
    "            fill_mode=\"constant\",\n",
    "            shear_range=0.2,\n",
    "            zoom_range=(0.5, 1),\n",
    "            horizontal_flip=True,\n",
    "            rotation_range=360,\n",
    "            channel_shift_range=25,\n",
    "            brightness_range=(0.75, 1.25))\n",
    "\n",
    "        # Validation image augmentation\n",
    "        val_data_generator = ImageDataGenerator(\n",
    "            rescale=1. / 255,\n",
    "            fill_mode=\"constant\",\n",
    "            shear_range=0.2,\n",
    "            zoom_range=(0.5, 1),\n",
    "            horizontal_flip=True,\n",
    "            rotation_range=360,\n",
    "            channel_shift_range=25,\n",
    "            brightness_range=(0.75, 1.25))\n",
    "\n",
    "        # No testing image augmentation (except for converting pixel values to floats)\n",
    "        test_data_generator = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "        # Load train images in batches from directory and apply augmentations\n",
    "        train_data_generator = train_data_generator.flow_from_dataframe(\n",
    "            train_dataframe,\n",
    "            IMG_DIRECTORY,\n",
    "            x_col='Filename',\n",
    "            y_col='Label',\n",
    "            target_size=RAW_IMG_SIZE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            has_ext=True,\n",
    "            classes=CLASSES,\n",
    "            class_mode='categorical')\n",
    "\n",
    "        # Load validation images in batches from directory and apply rescaling\n",
    "        val_data_generator = val_data_generator.flow_from_dataframe(\n",
    "            val_dataframe,\n",
    "            IMG_DIRECTORY,\n",
    "            x_col=\"Filename\",\n",
    "            y_col=\"Label\",\n",
    "            target_size=RAW_IMG_SIZE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            has_ext=True,\n",
    "            classes=CLASSES,\n",
    "            class_mode='categorical')\n",
    "\n",
    "        # Load test images in batches from directory and apply rescaling\n",
    "        test_data_generator = test_data_generator.flow_from_dataframe(\n",
    "            test_dataframe,\n",
    "            IMG_DIRECTORY,\n",
    "            x_col=\"Filename\",\n",
    "            y_col=\"Label\",\n",
    "            target_size=IMG_SIZE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            has_ext=True,\n",
    "            shuffle=False,\n",
    "            classes=CLASSES,\n",
    "            class_mode='categorical')\n",
    "\n",
    "        # Crop augmented images from 256x256 to 224x224\n",
    "        train_data_generator = crop_generator(train_data_generator, IMG_SIZE)\n",
    "        val_data_generator = crop_generator(val_data_generator, IMG_SIZE)\n",
    "\n",
    "        # Load ImageNet pre-trained model with no top, either InceptionV3 or ResNet50\n",
    "        if model_name == \"resnet\":\n",
    "            base_model = ResNet50(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
    "        elif model_name == \"inception\":\n",
    "            base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
    "        x = base_model.output\n",
    "        # Add a global average pooling layer\n",
    "        x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "        # Add fully connected output layer with sigmoid activation for multi label classification\n",
    "        outputs = Dense(len(CLASSES), activation='sigmoid', name='fc9')(x)\n",
    "        # Assemble the modified model\n",
    "        model = Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "        # Checkpoints for training\n",
    "        model_checkpoint = ModelCheckpoint(output_directory + \"lastbest-0.hdf5\", verbose=1, save_best_only=True)\n",
    "        early_stopping = EarlyStopping(patience=STOPPING_PATIENCE, restore_best_weights=True)\n",
    "        tensorboard = TensorBoard(log_dir=output_directory, histogram_freq=0, write_graph=True, write_images=False)\n",
    "        reduce_lr = ReduceLROnPlateau('val_loss', factor=0.5, patience=LR_PATIENCE, min_lr=0.000003125)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(lr=INITIAL_LR), metrics=['categorical_accuracy'])\n",
    "        csv_logger = CSVLogger(output_directory + \"training_metrics.csv\")\n",
    "\n",
    "        # Train model until MAX_EPOCH, restarting after each early stop when learning has plateaued\n",
    "        global_epoch = 0\n",
    "        restarts = 0\n",
    "        last_best_losses = []\n",
    "        last_best_epochs = []\n",
    "        while global_epoch < MAX_EPOCH:\n",
    "            history = model.fit_generator(\n",
    "                generator=train_data_generator,\n",
    "                steps_per_epoch=train_image_count // BATCH_SIZE,\n",
    "                epochs=MAX_EPOCH - global_epoch,\n",
    "                validation_data=val_data_generator,\n",
    "                validation_steps=val_image_count // BATCH_SIZE,\n",
    "                callbacks=[tensorboard, model_checkpoint, early_stopping, reduce_lr, csv_logger],\n",
    "                shuffle=False)\n",
    "            last_best_losses.append(min(history.history['val_loss']))\n",
    "            last_best_local_epoch = history.history['val_loss'].index(min(history.history['val_loss']))\n",
    "            last_best_epochs.append(global_epoch + last_best_local_epoch)\n",
    "            if early_stopping.stopped_epoch == 0:\n",
    "                print(\"Completed training after {} epochs.\".format(MAX_EPOCH))\n",
    "                break\n",
    "            else:\n",
    "                global_epoch = global_epoch + early_stopping.stopped_epoch - STOPPING_PATIENCE + 1\n",
    "                print(\"Early stopping triggered after local epoch {} (global epoch {}).\".format(\n",
    "                    early_stopping.stopped_epoch, global_epoch))\n",
    "                print(\"Restarting from last best val_loss at local epoch {} (global epoch {}).\".format(\n",
    "                    early_stopping.stopped_epoch - STOPPING_PATIENCE, global_epoch - STOPPING_PATIENCE))\n",
    "                restarts = restarts + 1\n",
    "                model.compile(loss='binary_crossentropy', optimizer=Adam(lr=INITIAL_LR / 2 ** restarts),\n",
    "                              metrics=['categorical_accuracy'])\n",
    "                model_checkpoint = ModelCheckpoint(output_directory + \"lastbest-{}.hdf5\".format(restarts),\n",
    "                                                   monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "        # Save last best model info\n",
    "        with open(output_directory + \"last_best_models.csv\", 'w', newline='') as file:\n",
    "            writer = csv.writer(file, delimiter=',')\n",
    "            writer.writerow(['Model file', 'Global epoch', 'Validation loss'])\n",
    "            for i in range(restarts + 1):\n",
    "                writer.writerow([\"lastbest-{}.hdf5\".format(i), last_best_epochs[i], last_best_losses[i]])\n",
    "\n",
    "        # Load the last best model\n",
    "        model = load_model(\n",
    "            output_directory + \"lastbest-{}.hdf5\".format(last_best_losses.index(min(last_best_losses))))\n",
    "\n",
    "        # Evaluate model on test subset for kth fold\n",
    "        predictions = model.predict_generator(test_data_generator, test_image_count // BATCH_SIZE + 1)\n",
    "        y_true = test_data_generator.classes\n",
    "        y_pred = np.argmax(predictions, axis=1)\n",
    "        y_pred[np.max(predictions, axis=1) < 1 / 9] = 8  # Assign predictions worse than random guess to negative class\n",
    "\n",
    "        # Generate and print classification metrics and confusion matrix\n",
    "        print(classification_report(y_true, y_pred, labels=CLASSES, target_names=CLASS_NAMES))\n",
    "        report = classification_report(y_true, y_pred, labels=CLASSES, target_names=CLASS_NAMES, output_dict=True)\n",
    "        with open(output_directory + 'classification_report.csv', 'w') as f:\n",
    "            for key in report.keys():\n",
    "                f.write(\"%s,%s\\n\" % (key, report[key]))\n",
    "        conf_arr = confusion_matrix(y_true, y_pred, labels=CLASSES)\n",
    "        print(conf_arr)\n",
    "        np.savetxt(output_directory + \"confusion_matrix.csv\", conf_arr, delimiter=\",\")\n",
    "\n",
    "        # Clear model from GPU after each iteration\n",
    "        print(\"Finished testing fold {}\\n\".format(k + 1))\n",
    "        K.clear_session()\n",
    "        k = k + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef1f215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model):\n",
    "\n",
    "    # Create new output directory for saving inference times\n",
    "    timestamp = datetime.fromtimestamp(time()).strftime('%Y%m%d-%H%M%S')\n",
    "    output_directory = \"{}{}/\".format(OUTPUT_DIRECTORY, timestamp)\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    # Load DeepWeeds dataframe\n",
    "    dataframe = pd.read_csv(LABEL_DIRECTORY + \"labels.csv\")\n",
    "    image_count = dataframe.shape[0]\n",
    "    filenames = dataframe.Filename\n",
    "\n",
    "    preprocessing_times = []\n",
    "    inference_times = []\n",
    "    for i in range(image_count):\n",
    "        # Load image\n",
    "        start_time = time()\n",
    "        img = imread(IMG_DIRECTORY + filenames[i])\n",
    "        # Resize to 224x224\n",
    "        img = resize(img, (224, 224))\n",
    "        # Map to batch\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        # Scale from int to float\n",
    "        img = img * 1./255\n",
    "        preprocessing_time = time() - start_time\n",
    "        start_time = time()\n",
    "        # Predict label\n",
    "        prediction = model.predict(img, batch_size=1, verbose=0)\n",
    "        y_pred = np.argmax(prediction, axis=1)\n",
    "        y_pred[np.max(prediction, axis=1) < 1/9] = 8\n",
    "        inference_time = time() - start_time\n",
    "        # Append times to lists\n",
    "        preprocessing_times.append(preprocessing_time)\n",
    "        inference_times.append(inference_time)\n",
    "\n",
    "    # Save inference times to csv\n",
    "    with open(output_directory + \"tf_inference_times.csv\", 'w', newline='') as file:\n",
    "        writer = csv.writer(file, delimiter=',')\n",
    "        writer.writerow(['Filename', 'Preprocessing time (ms)', 'Inference time (ms)'])\n",
    "        for i in range(image_count):\n",
    "            writer.writerow([filenames[i], preprocessing_times[i] * 1000, inference_times[i] * 1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffd9957",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "command='cross_validate'\n",
    "model='./models/inception.hdf5'\n",
    "    # Download images and models (if necessary)\n",
    "download_images()\n",
    "download_models()\n",
    "\n",
    "    #if command == \"cross_validate\":\n",
    "        #if not model == \"resnet\" and not model == \"inception\":\n",
    "        #    print(\"Error: You must ask for either \"\"resnet\"\" or \"\"inception\"\".\")\n",
    "        #else:\n",
    "            # Train and test model on DeepWeeds with 5 fold cross validation\n",
    "#cross_validate(model)\n",
    "  #  else:\n",
    "     #   if not model.endswith(\"hdf5\"):\n",
    "#            print(\"Error: You must supply a hdf5 model file to perform inference.\")\n",
    "       # else:\n",
    "            # Construct model from hdf5 model file\n",
    "model = load_model(model)\n",
    "            # Measure the speed of performing inference with the chosen model averaging over DeepWeeds images\n",
    "inference(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e031ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d275c31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5842ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
