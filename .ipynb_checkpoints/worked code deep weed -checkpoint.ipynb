{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4535d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c9a9ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbab1164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import argparse\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard, CSVLogger\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import csv\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras import backend as K\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D,Flatten\n",
    "import requests\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a7bfa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global paths\n",
    "OUTPUT_DIRECTORY = \"./outputs/\"\n",
    "LABEL_DIRECTORY = \"./labels/\"\n",
    "MODEL_DIRECTORY = \"./models/\"\n",
    "MODEL_GD_ID = \"1MRbN5hXOTYnw7-71K-2vjY01uJ9GkQM5\"\n",
    "MODEL_ZIP_FILE = \"./models/models.zip\"\n",
    "IMG_DIRECTORY = \"./images/\"\n",
    "IMG_GD_ID = \"1xnK3B6K6KekDI55vwJ0vnc2IGoDga9cj\"\n",
    "IMG_ZIP_FILE = \"./images/images.zip\"\n",
    "\n",
    "# Global variables\n",
    "RAW_IMG_SIZE = (256, 256)\n",
    "IMG_SIZE = (224, 224)\n",
    "INPUT_SHAPE = (IMG_SIZE[0], IMG_SIZE[1], 3)\n",
    "MAX_EPOCH = 1\n",
    "BATCH_SIZE = 8\n",
    "FOLDS = 5\n",
    "STOPPING_PATIENCE = 32\n",
    "LR_PATIENCE = 16\n",
    "INITIAL_LR = 0.0001\n",
    "CLASSES = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "CLASS_NAMES = ['Chinee Apple',\n",
    "               'Lantana',\n",
    "               'Parkinsonia',\n",
    "               'Parthenium',\n",
    "               'Prickly Acacia',\n",
    "               'Rubber Vine',\n",
    "               'Siam Weed',\n",
    "               'Snake Weed',\n",
    "               'Negatives']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5841d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def crop(img, size):\n",
    "    \"\"\"\n",
    "    Crop the image concentrically to the desired size.\n",
    "    :param img: Input image\n",
    "    :param size: Required crop image size\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    (h, w, c) = img.shape\n",
    "    x = int((w - size[0]) / 2)\n",
    "    y = int((h - size[1]) / 2)\n",
    "    return img[y:(y + size[1]), x:(x + size[0]), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "158c95c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_generator(batches, size):\n",
    "    \"\"\"\n",
    "    Take as input a Keras ImageGen (Iterator) and generate random\n",
    "    crops from the image batches generated by the original iterator\n",
    "    :param batches: Batches of images to be cropped\n",
    "    :param size: Size to be cropped to\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        batch_x, batch_y = next(batches)\n",
    "        (b, h, w, c) = batch_x.shape\n",
    "        batch_crops = np.zeros((b, size[0], size[1], c))\n",
    "        for i in range(b):\n",
    "            batch_crops[i] = crop(batch_x[i], (size[0], size[1]))\n",
    "        yield (batch_crops, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361d277d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede28a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e92bde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5 - 20220109-195836\n",
      "Found 10504 validated image filenames.\n",
      "Found 3502 validated image filenames.\n",
      "Found 3503 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "k=1\n",
    "        # Create new output directory for individual folds from timestamp\n",
    "timestamp = datetime.fromtimestamp(time()).strftime('%Y%m%d-%H%M%S')\n",
    "print('Fold {}/{} - {}'.format(k + 1, FOLDS, timestamp))\n",
    "output_directory = \"{}{}/\".format(OUTPUT_DIRECTORY, timestamp)\n",
    "if not os.path.exists(output_directory):\n",
    "            os.makedirs(output_directory)\n",
    "\n",
    "        # Prepare training, validation and testing labels for kth fold\n",
    "train_label_file = \"{}train_subset{}.csv\".format(LABEL_DIRECTORY, k)\n",
    "val_label_file = \"{}val_subset{}.csv\".format(LABEL_DIRECTORY, k)\n",
    "test_label_file = \"{}test_subset{}.csv\".format(LABEL_DIRECTORY, k)\n",
    "train_dataframe = pd.read_csv(train_label_file)\n",
    "val_dataframe = pd.read_csv(val_label_file)\n",
    "test_dataframe = pd.read_csv(test_label_file)\n",
    "train_image_count = train_dataframe.shape[0]\n",
    "val_image_count = train_dataframe.shape[0]\n",
    "test_image_count = test_dataframe.shape[0]\n",
    "\n",
    "        # Training image augmentation\n",
    "train_data_generator = ImageDataGenerator( rescale=1. / 255,  fill_mode=\"constant\", shear_range=0.2, zoom_range=(0.5, 1),\n",
    "horizontal_flip=True,rotation_range=360, channel_shift_range=25, brightness_range=(0.75, 1.25))\n",
    "\n",
    "        # Validation image augmentation\n",
    "val_data_generator = ImageDataGenerator(\n",
    "            rescale=1. / 255,\n",
    "            fill_mode=\"constant\",\n",
    "            shear_range=0.2,\n",
    "            zoom_range=(0.5, 1),\n",
    "            horizontal_flip=True,\n",
    "            rotation_range=360,\n",
    "            channel_shift_range=25,\n",
    "            brightness_range=(0.75, 1.25))\n",
    "\n",
    "        # No testing image augmentation (except for converting pixel values to floats)\n",
    "test_data_generator = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "        # Load train images in batches from directory and apply augmentations\n",
    "train_data_generator = train_data_generator.flow_from_dataframe(\n",
    "            train_dataframe,\n",
    "            IMG_DIRECTORY,\n",
    "            x_col='Filename',\n",
    "            y_col=\"Label\",\n",
    "            target_size=RAW_IMG_SIZE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            #has_ext=True,\n",
    "            classes=[0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
    "            class_mode='raw')\n",
    "\n",
    "        # Load validation images in batches from directory and apply rescaling\n",
    "val_data_generator = val_data_generator.flow_from_dataframe(\n",
    "            val_dataframe,\n",
    "            IMG_DIRECTORY,\n",
    "            x_col=\"Filename\",\n",
    "            y_col=\"Label\",\n",
    "            target_size=RAW_IMG_SIZE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            #has_ext=True,\n",
    "            classes=[0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
    "            class_mode='raw')\n",
    "\n",
    "        # Load test images in batches from directory and apply rescaling\n",
    "test_data_generator = test_data_generator.flow_from_dataframe(\n",
    "            test_dataframe,\n",
    "            IMG_DIRECTORY,\n",
    "            x_col=\"Filename\",\n",
    "            y_col=\"Label\",\n",
    "            target_size=IMG_SIZE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            #has_ext=True,\n",
    "            shuffle=False,\n",
    "            classes=[0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
    "            class_mode='raw')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c70a27e7",
   "metadata": {},
   "outputs": [],
   "source": [
    " train_data_generator = crop_generator(train_data_generator, IMG_SIZE)\n",
    "val_data_generator = crop_generator(val_data_generator, IMG_SIZE)\n",
    "\n",
    "        # Load ImageNet pre-trained model with no top, either InceptionV3 or ResNet50\n",
    "        #if model_name == \"resnet\":\n",
    "           # base_model = ResNet50(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
    "        #elif model_name == \"inception\":\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
    "x = base_model.output\n",
    "        # Add a global average pooling layer\n",
    "x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "        # Add fully connected output layer with sigmoid activation for multi label classification\n",
    "outputs = Dense(len(CLASSES), activation='sigmoid', name='fc9')(x)\n",
    "        # Assemble the modified model\n",
    "f=Flatten()(outputs)\n",
    "model = Model(inputs=base_model.input, outputs=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f345467",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(output_directory + \"lastbest-0.hdf5\", verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(patience=STOPPING_PATIENCE, restore_best_weights=True)\n",
    "tensorboard = TensorBoard(log_dir=output_directory, histogram_freq=0, write_graph=True, write_images=False)\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.5, patience=LR_PATIENCE, min_lr=0.000003125)\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=INITIAL_LR), metrics=['categorical_accuracy'])\n",
    "csv_logger = CSVLogger(output_directory + \"training_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64c02987",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASMAA\\AppData\\Local\\Temp/ipykernel_11972/81974102.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1313/1313 [==============================] - ETA: 0s - loss: -73.5010 - categorical_accuracy: 0.9997\n",
      "Epoch 00001: val_loss did not improve from -73.49086\n",
      "1313/1313 [==============================] - 401s 303ms/step - loss: -73.5010 - categorical_accuracy: 0.9997 - val_loss: -73.4709 - val_categorical_accuracy: 0.9973 - lr: 1.0000e-04\n",
      "Completed training after 1 epochs.\n"
     ]
    }
   ],
   "source": [
    "global_epoch = 0\n",
    "restarts = 0\n",
    "last_best_losses = []\n",
    "last_best_epochs = []\n",
    "while global_epoch < MAX_EPOCH:\n",
    "            history = model.fit_generator(\n",
    "                train_data_generator,\n",
    "                steps_per_epoch=train_image_count // BATCH_SIZE,\n",
    "                epochs=MAX_EPOCH - global_epoch,\n",
    "                validation_data=val_data_generator,\n",
    "                validation_steps=val_image_count // BATCH_SIZE,\n",
    "                callbacks=[tensorboard, model_checkpoint, early_stopping, reduce_lr, csv_logger],\n",
    "                shuffle=False)\n",
    "            last_best_losses.append(min(history.history['val_loss']))\n",
    "            last_best_local_epoch = history.history['val_loss'].index(min(history.history['val_loss']))\n",
    "            last_best_epochs.append(global_epoch + last_best_local_epoch)\n",
    "            if early_stopping.stopped_epoch == 0:\n",
    "                print(\"Completed training after {} epochs.\".format(MAX_EPOCH))\n",
    "                break\n",
    "            else:\n",
    "                global_epoch = global_epoch + early_stopping.stopped_epoch - STOPPING_PATIENCE + 1\n",
    "                print(\"Early stopping triggered after local epoch {} (global epoch {}).\".format(\n",
    "                    early_stopping.stopped_epoch, global_epoch))\n",
    "                print(\"Restarting from last best val_loss at local epoch {} (global epoch {}).\".format(\n",
    "                    early_stopping.stopped_epoch - STOPPING_PATIENCE, global_epoch - STOPPING_PATIENCE))\n",
    "                restarts = restarts + 1\n",
    "                model.compile(loss='binary_crossentropy', optimizer=Adam(lr=INITIAL_LR / 2 ** restarts),\n",
    "                              metrics=['categorical_accuracy'])\n",
    "                model_checkpoint = ModelCheckpoint(output_directory + \"lastbest-{}.hdf5\".format(restarts),\n",
    "                                                   monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d870e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_directory + \"last_best_models.csv\", 'w', newline='') as file:\n",
    "            writer = csv.writer(file, delimiter=',')\n",
    "            writer.writerow(['Model file', 'Global epoch', 'Validation loss'])\n",
    "            for i in range(restarts + 1):\n",
    "                writer.writerow([\"lastbest-{}.hdf5\".format(i), last_best_epochs[i], last_best_losses[i]])\n",
    "\n",
    "        # Load the last best model\n",
    "model = load_model(\n",
    "output_directory + \"lastbest-{}.hdf5\".format(last_best_losses.index(min(last_best_losses))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c7d08f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASMAA\\AppData\\Local\\Temp/ipykernel_11972/3848337285.py:2: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  predictions = model.predict_generator(test_data_generator, test_image_count // BATCH_SIZE + 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        # Evaluate model on test subset for kth fold\n",
    "predictions = model.predict_generator(test_data_generator, test_image_count // BATCH_SIZE + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61d7010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9cbe70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "  Chinee Apple       0.06      1.00      0.12       225\n",
      "       Lantana       0.00      0.00      0.00       213\n",
      "   Parkinsonia       0.00      0.00      0.00       206\n",
      "    Parthenium       0.00      0.00      0.00       205\n",
      "Prickly Acacia       0.00      0.00      0.00       213\n",
      "   Rubber Vine       0.00      0.00      0.00       202\n",
      "     Siam Weed       0.00      0.00      0.00       215\n",
      "    Snake Weed       0.00      0.00      0.00       203\n",
      "     Negatives       1.00      0.00      0.00      1821\n",
      "\n",
      "      accuracy                           0.06      3503\n",
      "     macro avg       0.12      0.11      0.01      3503\n",
      "  weighted avg       0.52      0.06      0.01      3503\n",
      "\n",
      "[[ 224    1    0    0    0    0    0    0    0]\n",
      " [ 212    0    0    0    0    1    0    0    0]\n",
      " [ 205    0    0    0    1    0    0    0    0]\n",
      " [ 205    0    0    0    0    0    0    0    0]\n",
      " [ 213    0    0    0    0    0    0    0    0]\n",
      " [ 202    0    0    0    0    0    0    0    0]\n",
      " [ 215    0    0    0    0    0    0    0    0]\n",
      " [ 203    0    0    0    0    0    0    0    0]\n",
      " [1802    3   12    1    0    0    2    0    1]]\n",
      "Finished testing fold 2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASMAA\\anaconda3\\envs\\Gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ASMAA\\anaconda3\\envs\\Gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ASMAA\\anaconda3\\envs\\Gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ASMAA\\anaconda3\\envs\\Gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ASMAA\\anaconda3\\envs\\Gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ASMAA\\anaconda3\\envs\\Gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#y_true = test_data_generator.classes\n",
    "y_true=test_data_generator.labels\n",
    "\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_pred[np.max(predictions, axis=1) < 1 / 9] = 8  # Assign predictions worse than random guess to negative class\n",
    "\n",
    "        # Generate and print classification metrics and confusion matrix\n",
    "print(classification_report(y_true, y_pred, labels=CLASSES, target_names=CLASS_NAMES))\n",
    "report = classification_report(y_true, y_pred, labels=CLASSES, target_names=CLASS_NAMES, output_dict=True)\n",
    "with open(output_directory + 'classification_report.csv', 'w') as f:\n",
    "            for key in report.keys():\n",
    "                f.write(\"%s,%s\\n\" % (key, report[key]))\n",
    "conf_arr = confusion_matrix(y_true, y_pred, labels=CLASSES)\n",
    "print(conf_arr)\n",
    "np.savetxt(output_directory + \"confusion_matrix.csv\", conf_arr, delimiter=\",\")\n",
    "\n",
    "        # Clear model from GPU after each iteration\n",
    "print(\"Finished testing fold {}\\n\".format(k + 1))\n",
    "K.clear_session()\n",
    "k = k + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2c51cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
